---
title: "Project 6"
author: "Juliette Dashe"
date: "2025-11-15"
output: html_document
---
```{r}


student_depression_dataset$id <- NULL
student_depression_dataset$`Work Pressure` <- NULL
student_depression_dataset$`Job Satisfaction` <- NULL
student_depression_dataset$Profession <- NULL

table(student_depression_dataset$Degree)


names(student_depression_dataset)
```



```{r}

#Juliette's code
print(">>>")
```

```{r}
#Tanner's code

library(dplyr)
library(randomForest)

df <- read.csv("student_depression_dataset.csv")

rf_data <- df[, c(
  "Age",
  "Academic.Pressure",
  "Work.Pressure",
  "CGPA",
  "Study.Satisfaction",
  "Job.Satisfaction",
  "Work.Study.Hours",
  "Financial.Stress",
  "Depression"
)]

rf_data <- na.omit(rf_data)

rf_data$Depression <- as.factor(rf_data$Depression)

set.seed(445)
n <- nrow(rf_data)
train_idx <- sample(1:n, size = floor(0.7 * n))
train <- rf_data[train_idx, ]
test  <- rf_data[-train_idx, ]

set.seed(445)
rf_model <- randomForest(
  Depression ~ ., 
  data = train,
  ntree = 500,   
  mtry = 3,      
  importance = TRUE
)

rf_pred <- predict(rf_model, newdata = test)

rf_tab <- table(Predicted = rf_pred, Actual = test$Depression)
print(rf_tab)

rf_accuracy <- sum(diag(rf_tab)) / sum(rf_tab)
cat("Test set accuracy:", rf_accuracy, "\n")

varImpPlot(rf_model, main = "Variable Importance (Random Forest)")
```



```{r}

##----------------------------Munisa's code-----------------------------------------

df <- read.csv("student_depression_dataset.csv")

knn_data <- df[ , c(
  "Age",
  "Academic.Pressure",
  "Work.Pressure",
  "CGPA",
  "Study.Satisfaction",
  "Job.Satisfaction",
  "Work.Study.Hours",
  "Financial.Stress",
  "Depression"
)]

knn_data <- na.omit(knn_data)          # <<< NEW LINE
knn_data$Depression <- as.factor(knn_data$Depression)

## 1. Train / test split
set.seed(123)
n <- nrow(knn_data)
train_idx <- sample(1:n, size = floor(0.7 * n))

train <- knn_data[train_idx, ]
test  <- knn_data[-train_idx, ]

## 2. X and y
predictor_cols <- c(
  "Age",
  "Academic.Pressure",
  "Work.Pressure",
  "CGPA",
  "Study.Satisfaction",
  "Job.Satisfaction",
  "Work.Study.Hours",
  "Financial.Stress"
)

X_train <- train[ , predictor_cols]
X_test  <- test[ , predictor_cols]

X_train <- data.frame(lapply(X_train, as.numeric))
X_test  <- data.frame(lapply(X_test,  as.numeric))

y_train <- train$Depression
y_test  <- test$Depression

train_complete <- complete.cases(X_train) & !is.na(y_train)
test_complete  <- complete.cases(X_test)  & !is.na(y_test)

X_train <- X_train[train_complete, ]
y_train <- y_train[train_complete]

X_test  <- X_test[test_complete, ]
y_test  <- y_test[test_complete]

## 3. Scale
train_means <- apply(X_train, 2, mean, na.rm = TRUE)
train_sds   <- apply(X_train, 2, sd,   na.rm = TRUE)

X_train_scaled <- scale(X_train, center = train_means, scale = train_sds)
X_test_scaled  <- scale(X_test,  center = train_means, scale = train_sds)

## 4. KNN over several k
library(class)

k_values <- c(3, 5, 7, 9, 11, 15, 21)
acc_vec <- numeric(length(k_values))

set.seed(123)
for (i in seq_along(k_values)) {
  k <- k_values[i]
  pred_k <- knn(
    train = X_train_scaled,
    test  = X_test_scaled,
    cl    = y_train,
    k     = k
  )
  tab_k <- table(Predicted = pred_k, Actual = y_test)
  acc_vec[i] <- sum(diag(tab_k)) / sum(tab_k)
}

results <- data.frame(k = k_values, accuracy = acc_vec)
print(results)

best_idx <- which.max(acc_vec)
best_k <- k_values[best_idx]
best_k

best_pred <- knn(
  train = X_train_scaled,
  test  = X_test_scaled,
  cl    = y_train,
  k     = best_k
)

best_tab <- table(Predicted = best_pred, Actual = y_test)
best_tab
best_accuracy <- sum(diag(best_tab)) / sum(best_tab)
best_accuracy

## 5. Plot
plot(
  k_values, acc_vec, type = "b",
  xlab = "Number of Neighbors (k)",
  ylab = "Test Accuracy",
  main = "KNN Accuracy vs k for Student Depression"
)

```




```{r}
#Leah's code

#Importing Dataset
library(readr)
student_depression_dataset <- read_csv("student_depression_dataset.csv")

#Data Cleaning
student_depression_dataset$id <- NULL
student_depression_dataset$`Work Pressure` <- NULL
student_depression_dataset$`Job Satisfaction` <- NULL
student_depression_dataset$Profession <- NULL

#Juliette's Data Cleaning with Degree Currently Pursuing
library(dplyr)

df_clean <- student_depression_dataset |>
  mutate(
    # Making degrees into 5 categories 
    Academic_Level = case_when(
      # High School
      Degree == "'Class 12'" ~ "High School",
      
      # Bachelor's Degrees (including B.Pharm, B.Tech, MBBS, etc.)
      Degree %in% c("BE", "B.Arch", "BHM", "B.Com", "BSc", "B.Ed", "LLB", 
                    "B.Pharm", "B.Tech", "BA", "BBA", "BCA") ~ "Bachelor's",
      
      # Master's Degrees/Professional Doctorates
      Degree %in% c("MA", "MBA", "MBBS", "MCA", "LLM", "MD", "M.Com", 
                    "ME", "M.Ed", "MHM", "M.Pharm", "MSc", "M.Tech", "MBBS") ~ "Master's",
      
      # PhD
      Degree == "PhD" ~ "PhD",
      
      # Other/Unspecified
      Degree == "Others" ~ "Other",
      
      # Catch-whatever else I might be missing 
      TRUE ~ "Unknown"
    ),
    
    # Convert the new column to an ordered factor for consistent analysis
    Academic_Level = factor(Academic_Level, 
                            levels = c("High School", "Bachelor's", "Master's", "PhD", "Other", "Unknown"))
  )

cat("Frequency of new Academic Levels:\n")
df_clean |>
  count(Academic_Level) |>
  print()
```

```{r}
#Leah's code 2

#Plotting (not all useful but I tried all combos)
head(df_clean)

library(ggplot2)

#Scatterplots - dbl vs dbl values
#Age vs other predictors
ggplot(data = df_clean, aes(x = `Age`, y = `Academic Pressure`)) + geom_point()
ggplot(data = df_clean, aes(x = `Age`, y = `CGPA`)) + geom_point()
ggplot(data = df_clean, aes(x = `Age`, y = `Study Satisfaction`)) + geom_point()
ggplot(data = df_clean, aes(x = `Age`, y = `Work/Study Hours`)) + geom_point()
ggplot(data = df_clean, aes(x = `Age`, y = `Financial Stress`)) + geom_point()

#Academic Pressure vs other predictors
ggplot(data = df_clean, aes(x = `Academic Pressure`, y = `CGPA`)) + geom_point()
ggplot(data = df_clean, aes(x = `Academic Pressure`, y = `Study Satisfaction`)) + geom_point()
ggplot(data = df_clean, aes(x = `Academic Pressure`, y = `Work/Study Hours`)) + geom_point()
ggplot(data = df_clean, aes(x = `Academic Pressure`, y = `Financial Stress`)) + geom_point()

#CGPA vs other predictors
ggplot(data = df_clean, aes(x = `CGPA`, y = `Study Satisfaction`)) + geom_point()
ggplot(data = df_clean, aes(x = `CGPA`, y = `Work/Study Hours`)) + geom_point()
ggplot(data = df_clean, aes(x = `CGPA`, y = `Financial Stress`)) + geom_point()

#Study Satisfaction vs other predictors
ggplot(data = df_clean, aes(x = `Study Satisfaction`, y = `Work/Study Hours`)) + geom_point()
ggplot(data = df_clean, aes(x = `Study Satisfaction`, y = `Financial Stress`)) + geom_point()

#Work/Study Hours vs other predictors
ggplot(data = df_clean, aes(x = `Work/Study Hours`, y = `Financial Stress`)) + geom_point()
```
```{r}
#Leah's code 3

#Plotting
head(df_clean)

#Bar plots - chrs
ggplot(data = df_clean, aes(x = `Gender`)) + geom_bar()
ggplot(data = df_clean, aes(x = `City`)) + geom_bar()
ggplot(data = df_clean, aes(x = `Sleep Duration`)) + geom_bar()
ggplot(data = df_clean, aes(x = `Dietary Habits`)) + geom_bar()
ggplot(data = df_clean, aes(x = `Have you ever had suicidal thoughts ?`)) + geom_bar()
ggplot(data = df_clean, aes(x = `Academic_Level`)) + geom_bar()
```
```{r}
#Leah's code 4

#Plotting
head(df_clean)

#Boxplots - chr vs dbl
#Gender vs other predictors
ggplot(data = df_clean, aes(x = `Gender`, y = `Age`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Gender`, y = `Academic Pressure`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Gender`, y = `CGPA`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Gender`, y = `Study Satisfaction`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Gender`, y = `Work/Study Hours`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Gender`, y = `Financial Stress`)) + geom_boxplot()

#Sleep Duration vs other predictors
ggplot(data = df_clean, aes(x = `Sleep Duration`, y = `Age`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Sleep Duration`, y = `Academic Pressure`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Sleep Duration`, y = `CGPA`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Sleep Duration`, y = `Study Satisfaction`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Sleep Duration`, y = `Work/Study Hours`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Sleep Duration`, y = `Financial Stress`)) + geom_boxplot()

#Dietary Habits vs other predictors
ggplot(data = df_clean, aes(x = `Dietary Habits`, y = `Age`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Dietary Habits`, y = `Academic Pressure`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Dietary Habits`, y = `CGPA`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Dietary Habits`, y = `Study Satisfaction`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Dietary Habits`, y = `Work/Study Hours`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Dietary Habits`, y = `Financial Stress`)) + geom_boxplot()

#Suicidal thoughts vs other predictors
ggplot(data = df_clean, aes(x = `Have you ever had suicidal thoughts ?`, y = `Age`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Have you ever had suicidal thoughts ?`, y = `Academic Pressure`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Have you ever had suicidal thoughts ?`, y = `CGPA`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Have you ever had suicidal thoughts ?`, y = `Study Satisfaction`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Have you ever had suicidal thoughts ?`, y = `Work/Study Hours`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Have you ever had suicidal thoughts ?`, y = `Financial Stress`)) + geom_boxplot()

#Family History of Mental Illness vs other predictors
ggplot(data = df_clean, aes(x = `Family History of Mental Illness`, y = `Age`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Family History of Mental Illness`, y = `Academic Pressure`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Family History of Mental Illness`, y = `CGPA`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Family History of Mental Illness`, y = `Study Satisfaction`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Family History of Mental Illness`, y = `Work/Study Hours`)) + geom_boxplot()
ggplot(data = df_clean, aes(x = `Family History of Mental Illness`, y = `Financial Stress`)) + geom_boxplot()
```
```{r}
#Leah's code 5

#Plotting
head(df_clean)

#Histograms - dbls
ggplot(data = df_clean, aes(x = `Age`)) + geom_histogram()
ggplot(data = df_clean, aes(x = `Academic Pressure`)) + geom_histogram()
ggplot(data = df_clean, aes(x = `CGPA`)) + geom_histogram()
ggplot(data = df_clean, aes(x = `Study Satisfaction`)) + geom_histogram()
ggplot(data = df_clean, aes(x = `Work/Study Hours`)) + geom_histogram()
ggplot(data = df_clean, aes(x = `Financial Stress`)) + geom_histogram()
```
```{r}
#Leah's code 6

#Logistic regression

library(tidyverse)
#Getting data ready to use glm()
df_clean <- df_clean %>%
  mutate(across(where(is.character), as.factor))
df_clean$City <- fct_lump(df_clean$City, n = 10)

#Splitting training and testing data
training_index <- sample(1:nrow(df_clean), 0.8 * nrow(df_clean))
train <- df_clean[training_index, ]
test  <- df_clean[-training_index, ]

factor_cols <- names(Filter(is.factor, train))
for (col in factor_cols) {
  test[[col]] <- factor(test[[col]], levels = levels(train[[col]]))
}

test <- test %>% drop_na(`Financial Stress`)

#Model 1
model1 <- glm(Depression ~ `Gender`, data = train, family = 'binomial')
probability1 <- predict(model1, test, type = 'response')
prediction1 <- ifelse(probability1 > 0.5, 1, 0)
actual_class1 <- mean(prediction1 == test$Depression)
actual_class1

#Model 2
model2 <- glm(Depression ~ `Gender` + `Age`, data = train, family = 'binomial')
probability2 <- predict(model2, test, type = 'response')
prediction2 <- ifelse(probability2 > 0.5, 1, 0)
actual_class2 <- mean(prediction2 == test$Depression)
actual_class2

#Model 3
model3 <- glm(Depression ~ `Gender` + `Age` + `City`, data = train, family = 'binomial')
probability3 <- predict(model3, test, type = 'response')
prediction3 <- ifelse(probability3 > 0.5, 1, 0)
actual_class3 <- mean(prediction3 == test$Depression)
actual_class3

#Model 4
model4 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure`, data = train, family = 'binomial')
probability4 <- predict(model4, test, type = 'response')
prediction4 <- ifelse(probability4 > 0.5, 1, 0)
actual_class4 <- mean(prediction4 == test$Depression)
actual_class4

#Model 5
model5 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA`, data = train, family = 'binomial')
probability5 <- predict(model5, test, type = 'response')
prediction5 <- ifelse(probability5 > 0.5, 1, 0)
actual_class5 <- mean(prediction5 == test$Depression)
actual_class5

#Model 6
model6 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction`, data = train, family = 'binomial')
probability6 <- predict(model6, test, type = 'response')
prediction6 <- ifelse(probability6 > 0.5, 1, 0)
actual_class6 <- mean(prediction6 == test$Depression)
actual_class6

#Model 7
model7 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration`, data = train, family = 'binomial')
probability7 <- predict(model7, test, type = 'response')
prediction7 <- ifelse(probability7 > 0.5, 1, 0)
actual_class7 <- mean(prediction7 == test$Depression)
actual_class7

#Model 8
model8 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits`, data = train, family = 'binomial')
probability8 <- predict(model8, test, type = 'response')
prediction8 <- ifelse(probability8 > 0.5, 1, 0)
actual_class8 <- mean(prediction8 == test$Depression)
actual_class8

#Model 9
model9 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?`, data = train, family = 'binomial')
probability9 <- predict(model9, test, type = 'response')
prediction9 <- ifelse(probability9 > 0.5, 1, 0)
actual_class9 <- mean(prediction9 == test$Depression)
actual_class9

#Model 10
model10 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?` + `Work/Study Hours`, data = train, family = 'binomial')
probability10 <- predict(model10, test, type = 'response')
prediction10 <- ifelse(probability10 > 0.5, 1, 0)
actual_class10 <- mean(prediction10 == test$Depression)
actual_class10

#Model 11
model11 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?` + `Work/Study Hours` + `Financial Stress`, data = train, family = 'binomial')
probability11 <- predict(model11, test, type = 'response')
prediction11 <- ifelse(probability11 > 0.5, 1, 0)
actual_class11 <- mean(prediction11 == test$Depression)
actual_class11

#Model 12
model12 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?` + `Work/Study Hours` + `Financial Stress` + `Family History of Mental Illness`, data = train, family = 'binomial')
probability12 <- predict(model12, test, type = 'response')
prediction12 <- ifelse(probability12 > 0.5, 1, 0)
actual_class12 <- mean(prediction12 == test$Depression)
actual_class12

#Model 13
model13 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?` + `Work/Study Hours` + `Financial Stress` + `Family History of Mental Illness` + `Academic_Level`, data = train, family = 'binomial')
probability13 <- predict(model13, test, type = 'response')
prediction13 <- ifelse(probability13 > 0.5, 1, 0)
actual_class13 <- mean(prediction13 == test$Depression)
actual_class13

#Model 14 with interaction 1
model14 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?` + `Work/Study Hours` + `Financial Stress` + `Family History of Mental Illness` + `Academic_Level` + `Academic Pressure`*`Academic_Level`, data = train, family = 'binomial')
probability14 <- predict(model14, test, type = 'response')
prediction14 <- ifelse(probability14 > 0.5, 1, 0)
actual_class14 <- mean(prediction14 == test$Depression)
actual_class14

#Model 15 with interaction 2
model15 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?` + `Work/Study Hours` + `Financial Stress` + `Family History of Mental Illness` + `Academic_Level` + `Sleep Duration`*`Work/Study Hours`, data = train, family = 'binomial')
probability15 <- predict(model15, test, type = 'response')
prediction15 <- ifelse(probability15 > 0.5, 1, 0)
actual_class15 <- mean(prediction15 == test$Depression)
actual_class15

#Model 16 with interaction 3
model16 <- glm(Depression ~ `Gender` + `Age` + `City` + `Academic Pressure` + `CGPA` + `Study Satisfaction` + `Sleep Duration` + `Dietary Habits` + `Have you ever had suicidal thoughts ?` + `Work/Study Hours` + `Financial Stress` + `Family History of Mental Illness` + `Academic_Level` + `Family History of Mental Illness`*`Have you ever had suicidal thoughts ?`, data = train, family = 'binomial')
probability16 <- predict(model16, test, type = 'response')
prediction16 <- ifelse(probability16 > 0.5, 1, 0)
actual_class16 <- mean(prediction16 == test$Depression)
actual_class16

#Comparing results of cross-validation
library(knitr)

results_vector <- c(actual_class1, actual_class2, actual_class3, actual_class4, actual_class5, actual_class6, actual_class7, actual_class8, actual_class9, actual_class10, actual_class11, actual_class12, actual_class13, actual_class14, actual_class15, actual_class16)
number_predictors <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)
results_df <- data.frame(Model = paste0("Model", 1:16), Predictors = number_predictors, Accuracy = results_vector)
kable(results_df, caption = "Comparing Logistic Models")
```

